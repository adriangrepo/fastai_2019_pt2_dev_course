{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "GPUID='1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=GPUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import uuid\n",
    "#export\n",
    "import time\n",
    "#pip3 install psutil\n",
    "import psutil\n",
    "from exp.nb_formatted import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set to true on first run\n",
    "RETRAIN=False\n",
    "#max mem use for weights in GB in RAM:\n",
    "MAX_MEM=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory use: 2.38287353515625\n"
     ]
    }
   ],
   "source": [
    "pid = os.getpid()\n",
    "py = psutil.Process(pid)\n",
    "memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "print('memory use:', memoryUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base, shallow, deep\n",
    "HOOK_DEPTH = 'base'\n",
    "CURRENT_DATE = datetime.datetime.today().strftime('%Y%m%d')\n",
    "UID=str(uuid.uuid4())[:8]\n",
    "NAME=HOOK_DEPTH+'_'+CURRENT_DATE+'_'+UID+'_'+GPUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "IMG_PATH=os.path.abspath(cwd + \"/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/963GB/Data/Python/Courses/my_fastai/2019_pt2_dev_course/dl2/images'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store on ssd rather than in home folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGEWOOF_160, dest='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "bs = 64\n",
    "#bs = 512\n",
    "\n",
    "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
    "val_tfms = [make_rgb, CenterCrop(size), np_to_float]\n",
    "il = ImageList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
    "ll.valid.x.tfms = val_tfms\n",
    "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12954"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = LabelSmoothingCrossEntropy()\n",
    "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using imagenette norm on imagewoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(arch=xresnet18, data=data, loss_func=loss_func, opt_func=opt_func, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_1cycle(lr, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "pct_start = 0.5\n",
    "cbsched = sched_1cycle(lr, pct_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save out model so can use with pets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 x 2080ti, bs=256, epochs=10, elapsed: 115.17198395729065\n",
    "\n",
    "2 x 2080ti, bs=512, epochs=10, elapsed: 79.39946436882019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model weights\n",
      "tensor([-0.0019,  0.0097, -0.0056, -0.0109,  0.0048,  0.0073, -0.0170, -0.0088,\n",
      "         0.0120,  0.0037])\n"
     ]
    }
   ],
   "source": [
    "mdl_path = path/'models'\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "\n",
    "if RETRAIN:\n",
    "    start=time.time()\n",
    "    learn.model = torch.nn.DataParallel(learn.model, device_ids=[0,1, 2])\n",
    "    learn.fit(500, cbsched)\n",
    "    end=time.time()\n",
    "    print(f'elapsed: {end-start}')\n",
    "    st = learn.model.state_dict()\n",
    "\n",
    "    print(type(st))\n",
    "\n",
    "    #keys are names of the layers\n",
    "    print(', '.join(st.keys()))\n",
    "    print(path)\n",
    "\n",
    "    #It's also possible to save the whole model, including the architecture, \n",
    "    #but it gets quite fiddly and we don't recommend it. \n",
    "    #Instead, just save the parameters, and recreate the model directly.\n",
    "\n",
    "    #torch.save(st, mdl_path/'iw5')\n",
    "else:\n",
    "    print('Loading pre-trained model weights')\n",
    "    learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n",
    "    st = learn.model.state_dict()\n",
    "    print(st['10.bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = datasets.untar_data(datasets.URLs.PETS, dest='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/oxford-iiit-pet/annotations'),\n",
       " PosixPath('data/oxford-iiit-pet/images')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_path = pets/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = ImageList.from_files(pets_path, tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageList (7390 items)\n",
       "[PosixPath('data/oxford-iiit-pet/images/scottish_terrier_193.jpg'), PosixPath('data/oxford-iiit-pet/images/Bengal_173.jpg'), PosixPath('data/oxford-iiit-pet/images/boxer_147.jpg'), PosixPath('data/oxford-iiit-pet/images/pug_137.jpg'), PosixPath('data/oxford-iiit-pet/images/german_shorthaired_54.jpg'), PosixPath('data/oxford-iiit-pet/images/Ragdoll_88.jpg'), PosixPath('data/oxford-iiit-pet/images/english_setter_120.jpg'), PosixPath('data/oxford-iiit-pet/images/great_pyrenees_120.jpg'), PosixPath('data/oxford-iiit-pet/images/British_Shorthair_212.jpg'), PosixPath('data/oxford-iiit-pet/images/leonberger_155.jpg')...]\n",
       "Path: data/oxford-iiit-pet/images"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont have a sapratae validation directory so randomly grab val samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_splitter(fn, p_valid): return random.random() < p_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: ImageList (6667 items)\n",
       "[PosixPath('data/oxford-iiit-pet/images/scottish_terrier_193.jpg'), PosixPath('data/oxford-iiit-pet/images/boxer_147.jpg'), PosixPath('data/oxford-iiit-pet/images/pug_137.jpg'), PosixPath('data/oxford-iiit-pet/images/german_shorthaired_54.jpg'), PosixPath('data/oxford-iiit-pet/images/Ragdoll_88.jpg'), PosixPath('data/oxford-iiit-pet/images/english_setter_120.jpg'), PosixPath('data/oxford-iiit-pet/images/British_Shorthair_212.jpg'), PosixPath('data/oxford-iiit-pet/images/chihuahua_132.jpg'), PosixPath('data/oxford-iiit-pet/images/staffordshire_bull_terrier_59.jpg'), PosixPath('data/oxford-iiit-pet/images/chihuahua_127.jpg')...]\n",
       "Path: data/oxford-iiit-pet/images\n",
       "Valid: ImageList (723 items)\n",
       "[PosixPath('data/oxford-iiit-pet/images/Bengal_173.jpg'), PosixPath('data/oxford-iiit-pet/images/great_pyrenees_120.jpg'), PosixPath('data/oxford-iiit-pet/images/leonberger_155.jpg'), PosixPath('data/oxford-iiit-pet/images/Siamese_84.jpg'), PosixPath('data/oxford-iiit-pet/images/beagle_153.jpg'), PosixPath('data/oxford-iiit-pet/images/scottish_terrier_37.jpg'), PosixPath('data/oxford-iiit-pet/images/japanese_chin_172.jpg'), PosixPath('data/oxford-iiit-pet/images/japanese_chin_59.jpg'), PosixPath('data/oxford-iiit-pet/images/great_pyrenees_155.jpg'), PosixPath('data/oxford-iiit-pet/images/yorkshire_terrier_50.jpg')...]\n",
       "Path: data/oxford-iiit-pet/images"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to label - use filenames as cant use folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scottish_terrier_193.jpg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = il.items[0].name; n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scottish_terrier'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)_\\d+.jpg$', n)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pet_labeler(fn): \n",
    "    return re.findall(r'^(.*)_\\d+.jpg$', fn.name)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CategoryProcessor from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = CategoryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = label_by_func(sd, pet_labeler, proc_y=proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scottish_terrier, boxer, pug, german_shorthaired, Ragdoll, english_setter, British_Shorthair, chihuahua, staffordshire_bull_terrier, Maine_Coon, pomeranian, american_pit_bull_terrier, yorkshire_terrier, Bengal, saint_bernard, Birman, Abyssinian, Bombay, Siamese, keeshond, beagle, american_bulldog, shiba_inu, wheaten_terrier, leonberger, basset_hound, great_pyrenees, japanese_chin, Russian_Blue, Sphynx, havanese, Egyptian_Mau, english_cocker_spaniel, samoyed, newfoundland, miniature_pinscher, Persian'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(proc.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.valid.x.tfms = val_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out = len(proc.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ll.to_databunch(bs, c_in=3, c_out=c_out, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    learn.fit(5, cbsched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "epoch \ttrain_loss \ttrain_accuracy \tvalid_loss \tvalid_accuracy \ttime\n",
    "0 \t3.467661 \t0.083246 \t3.488343 \t0.095436 \t00:07\n",
    "1 \t3.303485 \t0.126594 \t3.571582 \t0.112033 \t00:07\n",
    "2 \t3.123925 \t0.179691 \t3.204137 \t0.159059 \t00:07\n",
    "3 \t2.826835 \t0.265037 \t2.929686 \t0.250346 \t00:07\n",
    "4 \t2.544567 \t0.360582 \t2.638438 \t0.355463 \t00:07\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor result above, here we read in imagewoof model and customise for pets. Create 10 activations at end.\n",
    "\n",
    "Also addpend Recorder callback to access loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette, xtra_cb=Recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/imagewoof-160/models')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = torch.load(mdl_path/'iw5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.0.weight', '0.1.weight', '0.1.bias', '0.1.running_mean', '0.1.running_var', '0.1.num_batches_tracked', '1.0.weight', '1.1.weight', '1.1.bias', '1.1.running_mean', '1.1.running_var', '1.1.num_batches_tracked', '2.0.weight', '2.1.weight', '2.1.bias', '2.1.running_mean', '2.1.running_var', '2.1.num_batches_tracked', '4.0.convs.0.0.weight', '4.0.convs.0.1.weight', '4.0.convs.0.1.bias', '4.0.convs.0.1.running_mean', '4.0.convs.0.1.running_var', '4.0.convs.0.1.num_batches_tracked', '4.0.convs.1.0.weight', '4.0.convs.1.1.weight', '4.0.convs.1.1.bias', '4.0.convs.1.1.running_mean', '4.0.convs.1.1.running_var', '4.0.convs.1.1.num_batches_tracked', '4.1.convs.0.0.weight', '4.1.convs.0.1.weight', '4.1.convs.0.1.bias', '4.1.convs.0.1.running_mean', '4.1.convs.0.1.running_var', '4.1.convs.0.1.num_batches_tracked', '4.1.convs.1.0.weight', '4.1.convs.1.1.weight', '4.1.convs.1.1.bias', '4.1.convs.1.1.running_mean', '4.1.convs.1.1.running_var', '4.1.convs.1.1.num_batches_tracked', '5.0.convs.0.0.weight', '5.0.convs.0.1.weight', '5.0.convs.0.1.bias', '5.0.convs.0.1.running_mean', '5.0.convs.0.1.running_var', '5.0.convs.0.1.num_batches_tracked', '5.0.convs.1.0.weight', '5.0.convs.1.1.weight', '5.0.convs.1.1.bias', '5.0.convs.1.1.running_mean', '5.0.convs.1.1.running_var', '5.0.convs.1.1.num_batches_tracked', '5.0.idconv.0.weight', '5.0.idconv.1.weight', '5.0.idconv.1.bias', '5.0.idconv.1.running_mean', '5.0.idconv.1.running_var', '5.0.idconv.1.num_batches_tracked', '5.1.convs.0.0.weight', '5.1.convs.0.1.weight', '5.1.convs.0.1.bias', '5.1.convs.0.1.running_mean', '5.1.convs.0.1.running_var', '5.1.convs.0.1.num_batches_tracked', '5.1.convs.1.0.weight', '5.1.convs.1.1.weight', '5.1.convs.1.1.bias', '5.1.convs.1.1.running_mean', '5.1.convs.1.1.running_var', '5.1.convs.1.1.num_batches_tracked', '6.0.convs.0.0.weight', '6.0.convs.0.1.weight', '6.0.convs.0.1.bias', '6.0.convs.0.1.running_mean', '6.0.convs.0.1.running_var', '6.0.convs.0.1.num_batches_tracked', '6.0.convs.1.0.weight', '6.0.convs.1.1.weight', '6.0.convs.1.1.bias', '6.0.convs.1.1.running_mean', '6.0.convs.1.1.running_var', '6.0.convs.1.1.num_batches_tracked', '6.0.idconv.0.weight', '6.0.idconv.1.weight', '6.0.idconv.1.bias', '6.0.idconv.1.running_mean', '6.0.idconv.1.running_var', '6.0.idconv.1.num_batches_tracked', '6.1.convs.0.0.weight', '6.1.convs.0.1.weight', '6.1.convs.0.1.bias', '6.1.convs.0.1.running_mean', '6.1.convs.0.1.running_var', '6.1.convs.0.1.num_batches_tracked', '6.1.convs.1.0.weight', '6.1.convs.1.1.weight', '6.1.convs.1.1.bias', '6.1.convs.1.1.running_mean', '6.1.convs.1.1.running_var', '6.1.convs.1.1.num_batches_tracked', '7.0.convs.0.0.weight', '7.0.convs.0.1.weight', '7.0.convs.0.1.bias', '7.0.convs.0.1.running_mean', '7.0.convs.0.1.running_var', '7.0.convs.0.1.num_batches_tracked', '7.0.convs.1.0.weight', '7.0.convs.1.1.weight', '7.0.convs.1.1.bias', '7.0.convs.1.1.running_mean', '7.0.convs.1.1.running_var', '7.0.convs.1.1.num_batches_tracked', '7.0.idconv.0.weight', '7.0.idconv.1.weight', '7.0.idconv.1.bias', '7.0.idconv.1.running_mean', '7.0.idconv.1.running_var', '7.0.idconv.1.num_batches_tracked', '7.1.convs.0.0.weight', '7.1.convs.0.1.weight', '7.1.convs.0.1.bias', '7.1.convs.0.1.running_mean', '7.1.convs.0.1.running_var', '7.1.convs.0.1.num_batches_tracked', '7.1.convs.1.0.weight', '7.1.convs.1.1.weight', '7.1.convs.1.1.bias', '7.1.convs.1.1.running_mean', '7.1.convs.1.1.running_var', '7.1.convs.1.1.num_batches_tracked', '10.weight', '10.bias'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.0.weight', '0.1.weight', '0.1.bias', '0.1.running_mean', '0.1.running_var', '0.1.num_batches_tracked', '1.0.weight', '1.1.weight', '1.1.bias', '1.1.running_mean', '1.1.running_var', '1.1.num_batches_tracked', '2.0.weight', '2.1.weight', '2.1.bias', '2.1.running_mean', '2.1.running_var', '2.1.num_batches_tracked', '4.0.convs.0.0.weight', '4.0.convs.0.1.weight', '4.0.convs.0.1.bias', '4.0.convs.0.1.running_mean', '4.0.convs.0.1.running_var', '4.0.convs.0.1.num_batches_tracked', '4.0.convs.1.0.weight', '4.0.convs.1.1.weight', '4.0.convs.1.1.bias', '4.0.convs.1.1.running_mean', '4.0.convs.1.1.running_var', '4.0.convs.1.1.num_batches_tracked', '4.1.convs.0.0.weight', '4.1.convs.0.1.weight', '4.1.convs.0.1.bias', '4.1.convs.0.1.running_mean', '4.1.convs.0.1.running_var', '4.1.convs.0.1.num_batches_tracked', '4.1.convs.1.0.weight', '4.1.convs.1.1.weight', '4.1.convs.1.1.bias', '4.1.convs.1.1.running_mean', '4.1.convs.1.1.running_var', '4.1.convs.1.1.num_batches_tracked', '5.0.convs.0.0.weight', '5.0.convs.0.1.weight', '5.0.convs.0.1.bias', '5.0.convs.0.1.running_mean', '5.0.convs.0.1.running_var', '5.0.convs.0.1.num_batches_tracked', '5.0.convs.1.0.weight', '5.0.convs.1.1.weight', '5.0.convs.1.1.bias', '5.0.convs.1.1.running_mean', '5.0.convs.1.1.running_var', '5.0.convs.1.1.num_batches_tracked', '5.0.idconv.0.weight', '5.0.idconv.1.weight', '5.0.idconv.1.bias', '5.0.idconv.1.running_mean', '5.0.idconv.1.running_var', '5.0.idconv.1.num_batches_tracked', '5.1.convs.0.0.weight', '5.1.convs.0.1.weight', '5.1.convs.0.1.bias', '5.1.convs.0.1.running_mean', '5.1.convs.0.1.running_var', '5.1.convs.0.1.num_batches_tracked', '5.1.convs.1.0.weight', '5.1.convs.1.1.weight', '5.1.convs.1.1.bias', '5.1.convs.1.1.running_mean', '5.1.convs.1.1.running_var', '5.1.convs.1.1.num_batches_tracked', '6.0.convs.0.0.weight', '6.0.convs.0.1.weight', '6.0.convs.0.1.bias', '6.0.convs.0.1.running_mean', '6.0.convs.0.1.running_var', '6.0.convs.0.1.num_batches_tracked', '6.0.convs.1.0.weight', '6.0.convs.1.1.weight', '6.0.convs.1.1.bias', '6.0.convs.1.1.running_mean', '6.0.convs.1.1.running_var', '6.0.convs.1.1.num_batches_tracked', '6.0.idconv.0.weight', '6.0.idconv.1.weight', '6.0.idconv.1.bias', '6.0.idconv.1.running_mean', '6.0.idconv.1.running_var', '6.0.idconv.1.num_batches_tracked', '6.1.convs.0.0.weight', '6.1.convs.0.1.weight', '6.1.convs.0.1.bias', '6.1.convs.0.1.running_mean', '6.1.convs.0.1.running_var', '6.1.convs.0.1.num_batches_tracked', '6.1.convs.1.0.weight', '6.1.convs.1.1.weight', '6.1.convs.1.1.bias', '6.1.convs.1.1.running_mean', '6.1.convs.1.1.running_var', '6.1.convs.1.1.num_batches_tracked', '7.0.convs.0.0.weight', '7.0.convs.0.1.weight', '7.0.convs.0.1.bias', '7.0.convs.0.1.running_mean', '7.0.convs.0.1.running_var', '7.0.convs.0.1.num_batches_tracked', '7.0.convs.1.0.weight', '7.0.convs.1.1.weight', '7.0.convs.1.1.bias', '7.0.convs.1.1.running_mean', '7.0.convs.1.1.running_var', '7.0.convs.1.1.num_batches_tracked', '7.0.idconv.0.weight', '7.0.idconv.1.weight', '7.0.idconv.1.bias', '7.0.idconv.1.running_mean', '7.0.idconv.1.running_var', '7.0.idconv.1.num_batches_tracked', '7.1.convs.0.0.weight', '7.1.convs.0.1.weight', '7.1.convs.0.1.bias', '7.1.convs.0.1.running_mean', '7.1.convs.0.1.running_var', '7.1.convs.0.1.num_batches_tracked', '7.1.convs.1.0.weight', '7.1.convs.1.1.weight', '7.1.convs.1.1.bias', '7.1.convs.1.1.running_mean', '7.1.convs.1.1.running_var', '7.1.convs.1.1.num_batches_tracked', '10.weight', '10.bias'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mst.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that keys are same in both dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in st.keys() if k not in mst.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.load_state_dict(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to remove last layer as have different ammount of categries - here 37 pet breeds. Find the AdaptiveAvgPool2d layer and use everything before this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XResNet(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (idconv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (idconv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (idconv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=1)\n",
       "  (9): Flatten()\n",
       "  (10): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = next(i for i,o in enumerate(m.children()) if isinstance(o,nn.AdaptiveAvgPool2d))\n",
    "m_cut = m[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_grandchildren(model):\n",
    "    grandkids=[]\n",
    "    for m in m_cut.children():\n",
    "        for g in m.children():\n",
    "            grandkids.append(g)\n",
    "    return grandkids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gc = module_grandchildren(m_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = get_batch(data.valid_dl, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m_cut(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512, 4, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find number of inputs, here we have 128 minibatch of input size 512, 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of inputs to our head\n",
    "ni = pred.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we use both Avg and Max pool and concatenate them together eg\n",
    "https://www.cs.cmu.edu/~tzhi/publications/ICIP2016_two_stage.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=1):\n",
    "        super().__init__()\n",
    "        self.output_size = sz\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stat and plot functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histc()\n",
    "\n",
    "Computes the histogram of a tensor.\n",
    "        \n",
    "        The elements are sorted into equal width bins between :attr:`min` and\n",
    "        :attr:`max`. If :attr:`min` and :attr:`max` are both zero, the minimum and\n",
    "        maximum values of the data are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a global in the __main__ scope so we can track iterations\n",
    "stat_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as per lecture but with relu scale check\n",
    "def append_hist_stats(hook, mod, inp, outp):\n",
    "    global stat_iter\n",
    "    memoryUse=0\n",
    "    if not hasattr(hook,'stats'): \n",
    "        hook.stats = ([],[],[])\n",
    "    means,stds,hists = hook.stats\n",
    "    #mod 0 is XResNet object with properties:\n",
    "    #_backend, _backward_hooks,_buffers,_forward_hooks (this is where stats is located)\n",
    "    #,_load_state_dict_pre_hooks,_modules (87 sequentiol, 1 MaxPool2d)\n",
    "    #,_parameters,_state_dict_hooks\n",
    "    #then 1 AdaptiveConcatPool2d\n",
    "    #then 2 Flatten\n",
    "    #then 3 Linear (with shape [64,37])\n",
    "    if mod.training:\n",
    "        #eg outp.data shape is [64,512,4,4]\n",
    "        means.append(outp.data.mean().cpu())\n",
    "        stds.append(outp.data.std().cpu())\n",
    "        if isinstance(mod, nn.Linear):\n",
    "            hists.append(outp.data.cpu().histc(40,-10,10)) #no relu here\n",
    "        else:\n",
    "            hists.append(outp.data.cpu().histc(40,0,10)) #no negatives\n",
    "        if stat_iter<100:\n",
    "            print(f'iter: {stat_iter}, layer: {mod.__class__.__name__}, data shape: {outp.data.cpu().numpy().shape}')\n",
    "        stat_iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is run on each batch\n",
    "def append_hist_delta_stats(hook, mod, inp, outp):\n",
    "    global stat_iter\n",
    "    if not hasattr(hook,'stats'): \n",
    "        hook.stats = ([],[],[])\n",
    "    #keep previous batch data for calculating deltas\n",
    "    if not hasattr(hook,'prevdatas'): \n",
    "        hook.prevdatas = ([])\n",
    "    if not hasattr(hook,'hdeltas'): \n",
    "        hook.hdeltas = ([])\n",
    "    means,stds,hists = hook.stats\n",
    "    prevdata=hook.prevdatas\n",
    "    deltas = hook.hdeltas\n",
    "    if mod.training:\n",
    "        #eg outp.data shape is [64,512,4,4]\n",
    "        means.append(outp.data.mean().cpu())\n",
    "        stds.append(outp.data.std().cpu())\n",
    "        if len(prevdata)>0:\n",
    "            try:\n",
    "                delta=outp.data.cpu()-prevdata[0]\n",
    "            except RuntimeError as e:\n",
    "                #problem at end of batch when size of prev wont match current\n",
    "                delta=outp.data.cpu()\n",
    "        else:\n",
    "            delta=outp.data.cpu()\n",
    "        prevdata.append(outp.data.cpu())\n",
    "        if len(prevdata)>1:\n",
    "            #just keep the last one otherwise will overrun memory\n",
    "            prevdata=prevdata[-1]\n",
    "        deltas.append(delta.histc(40,-10,10))\n",
    "        if isinstance(mod, nn.Linear):\n",
    "            hists.append(outp.data.cpu().histc(40,-10,10)) #no relu here\n",
    "        else:\n",
    "            hists.append(outp.data.cpu().histc(40,0,10)) #no negatives\n",
    "        stat_iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#needs work before can use - far too much data to store without downsampling\n",
    "def append_raw_hist_stats(hook, mod, inp, outp):\n",
    "    global stat_iter\n",
    "    memoryUse=0\n",
    "    if not hasattr(hook,'stats'): \n",
    "        hook.stats = ([],[],[])\n",
    "    if not hasattr(hook,'raws'): \n",
    "        hook.raws = ([])\n",
    "    means,stds,hists = hook.stats\n",
    "    raws = hook.raws\n",
    "    if mod.training:\n",
    "        #eg outp.data shape is [64,512,4,4]\n",
    "        means.append(outp.data.mean().cpu())\n",
    "        stds.append(outp.data.std().cpu())\n",
    "        if (stat_iter % 100) == 0:\n",
    "            memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "        if memoryUse < MAX_MEM:\n",
    "            d = outp.data\n",
    "            if len(outp.data.shape)==4:\n",
    "                new_shape=outp.data.shape\n",
    "                #want 3 channels so can plot r,g,b\n",
    "                new_shape[-1]=3\n",
    "                #put channel as last dimension\n",
    "                d=d.permute(0, 2, 3, 1)\n",
    "                d=d.cpu().numpy()\n",
    "                #calc mean of the whole batch\n",
    "                d=d.mean(0)\n",
    "                #now coerce to 3 channels\n",
    "                d=bin_ndarray(d, new_shape, operation='mean')\n",
    "            #flatten and linear are dim 2 \n",
    "            #now take mean over last index to reduce size\n",
    "            else:\n",
    "                d=d.cpu().numpy()\n",
    "            raws.append(d.mean(-1))\n",
    "            if stat_iter==0:\n",
    "                print(f'data shape: {outp.data.cpu().numpy().shape}, size: {outp.data.cpu().numpy().size}, mean size: {outp.data.cpu().numpy().mean(-1).size}')\n",
    "        else:\n",
    "            print(f'oom appending: {outp.data.cpu().numpy().mean(-1).size}, {outp.data.cpu().numpy().shape}')\n",
    "        if isinstance(mod, nn.Linear):\n",
    "            hists.append(outp.data.cpu().histc(40,-10,10)) #no relu here\n",
    "        else:\n",
    "            hists.append(outp.data.cpu().histc(40,0,10)) #no negatives\n",
    "        if stat_iter<100:\n",
    "            print(f'iter: {stat_iter}, layer: {mod.__class__.__name__}, data shape: {outp.data.cpu().numpy().shape}')\n",
    "        stat_iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hooks(hooks, model, fig_name=None):\n",
    "    fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "    print(f'plotting {len(hooks)} layers')\n",
    "    i=0\n",
    "    first_len=0\n",
    "    for h,m in zip(hooks,model):\n",
    "        ms,ss, hists = h.stats\n",
    "        if i==0:\n",
    "            first_len=len(ms)\n",
    "        #print(f\"{i}, {str(m).split('(')[0]}: {len(ms)}\")\n",
    "        if str(m).split('(')[0]=='ReLU':\n",
    "        #data for Relu layer is 19 times longer than other layers, not sure why\n",
    "            ms=ms[:first_len] \n",
    "            ss=ss[:first_len] \n",
    "        ax0.plot(ms)\n",
    "        ax0.set_title('mean')\n",
    "        ax1.plot(ss)\n",
    "        ax1.set_title('std. dev.')\n",
    "        i+=1\n",
    "    if model:   \n",
    "        titles=[]\n",
    "        idxs=[]\n",
    "        for j,m in enumerate(learn.model):\n",
    "            titles.append(str(j)+' '+str(m).split('(')[0])\n",
    "        plt.legend(titles)\n",
    "    else:\n",
    "        plt.legend(range(len(hooks)))\n",
    "    if fig_name:\n",
    "        plt.savefig(IMG_PATH+'/'+NAME+'_'+fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_deltas(deltas, smoother, fig_name=None):\n",
    "    half_plots=int((len(deltas)/2) + (len(deltas)/2 % 1 > 0))\n",
    "    fig,axes= plt.subplots(half_plots,2, figsize=(10,half_plots*2))\n",
    "    for ax,h in zip(axes.flatten(), deltas):\n",
    "        h = smooth(h, smoother)\n",
    "        ax.plot(h)\n",
    "        ax.set_title('delta')\n",
    "    plt.legend(range(len(deltas)))\n",
    "    if fig_name:\n",
    "        plt.savefig(IMG_PATH+'/'+NAME+'_'+fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the hist data at index 2\n",
    "def get_hist(h): \n",
    "    assert len(h.stats)==3\n",
    "    return torch.stack(h.stats[2]).t().float().log1p().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_hist(h): \n",
    "    return torch.stack(h.hdeltas).t().float().log1p().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hooks_hist(hooks, fig_name=None, model=None):\n",
    "    #subplots(rows,colums)\n",
    "    half_plots=int((len(hooks)/2) + (len(hooks)/2 % 1 > 0))\n",
    "    fig,axes = plt.subplots(half_plots,2, figsize=(15,int(len(hooks)/2)*3))\n",
    "    i=0\n",
    "    for ax,h in zip(axes.flatten(), hooks):\n",
    "        ax.imshow(get_hist(h), origin='lower')\n",
    "        ax.imshow(get_hist(h))\n",
    "        ax.set_aspect('auto')\n",
    "        ax.axis('on')\n",
    "        if model:\n",
    "            for j,m in enumerate(learn.model):\n",
    "                if i == j:\n",
    "                    title=str(m).split('(')[0]\n",
    "                    ax.set_title(title)\n",
    "        i+=1\n",
    "    plt.tight_layout()\n",
    "    if fig_name:\n",
    "        plt.savefig(IMG_PATH+'/'+NAME+'_'+fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hooks_delta_hist(hooks, fig_name=None,model=None):\n",
    "    #subplots(rows,colums)\n",
    "    half_plots=int((len(hooks)/2) + (len(hooks)/2 % 1 > 0))\n",
    "    fig,axes = plt.subplots(half_plots,2, figsize=(15,int(len(hooks)/2)*3))\n",
    "    i=0\n",
    "    for ax,h in zip(axes.flatten(), hooks):\n",
    "        ax.imshow(get_delta_hist(h), origin='lower')\n",
    "        ax.imshow(get_delta_hist(h))\n",
    "        ax.set_aspect('auto')\n",
    "        ax.axis('on')\n",
    "        if model:\n",
    "            for j,m in enumerate(learn.model):\n",
    "                if i == j:\n",
    "                    title=str(m).split('(')[0]\n",
    "                    ax.set_title(title)\n",
    "        i+=1\n",
    "    plt.tight_layout()\n",
    "    if fig_name:\n",
    "        plt.savefig(IMG_PATH+'/'+NAME+'_'+fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hooks_hist_lines(hooks, fig_name=None):\n",
    "    half_plots=int((len(hooks)/2) + (len(hooks)/2 % 1 > 0))\n",
    "    fig,axes = plt.subplots(half_plots,2, figsize=(15,int(len(hooks)/2)*5))\n",
    "    for ax,h in zip(axes.flatten(), hooks):\n",
    "        ax.plot(get_hist(h))\n",
    "        ax.axis('on')\n",
    "    if fig_name:\n",
    "        plt.savefig(IMG_PATH+'/'+NAME+'_'+fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_mins(h):\n",
    "    h1 = torch.stack(h.stats[2]).t().float().cpu()\n",
    "    return h1[:2].sum(0)/h1.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mid_mins(h, max_hist):\n",
    "    h1 = torch.stack(h.stats[2]).t().float().cpu()\n",
    "    #get stats on middle bins of histogram data\n",
    "    return h1[int((max_hist/2)-1):int((max_hist/2)+2)].sum(0)/h1.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mins(hooks):\n",
    "    half_plots=int((len(hooks)/2) + (len(hooks)/2 % 1 > 0))\n",
    "    fig,axes = plt.subplots(half_plots,2, figsize=(15,int(len(hooks)/2)*2))\n",
    "    for ax,h in zip(axes.flatten(), hooks):\n",
    "        ax.plot(get_start_mins(h))\n",
    "        ax.set_ylim(0,1)\n",
    "        ax.axis('on')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mid_mins(hooks):\n",
    "    half_plots=int((len(hooks)/2) + (len(hooks)/2 % 1 > 0))\n",
    "    fig,axes = plt.subplots(half_plots,2, figsize=(15,int(len(hooks)/2)*2))\n",
    "    hist = get_hist(hooks[0])\n",
    "    max_hist=hist.shape[0]\n",
    "    print(max_hist)\n",
    "    for ax,h in zip(axes.flatten(), hooks):\n",
    "        ax.plot(get_mid_mins(h,max_hist))\n",
    "        ax.set_ylim(-1,1)\n",
    "        ax.axis('on')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(['mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ep_vals(ep_vals, fig_name=None):\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    epochs = ep_vals.keys()\n",
    "    plt.xticks(np.asarray(list(epochs)))\n",
    "    trn_losses = [item[0] for item in list(ep_vals.values())]\n",
    "    val_losses = [item[1] for item in list(ep_vals.values())]\n",
    "    plt.plot(epochs, trn_losses, c='b', label='train')\n",
    "    plt.plot(epochs, val_losses, c='r', label='validation')\n",
    "    plt.legend(loc='upper left')\n",
    "    if fig_name:\n",
    "        plt.savefig(IMG_PATH+'/'+NAME+'_'+fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_layers(hooks):\n",
    "    for h in hooks:\n",
    "        print(len(h.raws))\n",
    "        h_raw_np=np.concatenate(h.raws, axis=0 )\n",
    "        plot_kernels(h_raw_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after Fchaubard https://discuss.pytorch.org/t/understanding-deep-network-visualize-weights/2060/7\n",
    "def plot_kernels(tensor, num_cols=6):\n",
    "    if isinstance(tensor, list):\n",
    "        print(len(tensor))\n",
    "        print(tensor[0].shape)\n",
    "    if not tensor.ndim==4:\n",
    "        #not plotting Flatten or Linear layers\n",
    "        return\n",
    "    if not tensor.shape[-1]==3:\n",
    "        raise Exception(\"last dim needs to be 3 to plot\")\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.imshow(tensor[i])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, model part: Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      ")\n",
      "i: 1, model part: Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      ")\n",
      "i: 2, model part: Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      ")\n",
      "i: 3, model part: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "i: 4, model part: Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "i: 5, model part: Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (idconv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (1): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "i: 6, model part: Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (idconv): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (1): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "i: 7, model part: Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (idconv): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (1): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "i: 8, model part: AdaptiveAvgPool2d(output_size=1)\n",
      "i: 9, model part: Flatten()\n",
      "i: 10, model part: Linear(in_features=512, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for i,m in enumerate(learn.model):\n",
    "    print(f'i: {i}, model part: {m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model change\n",
    "\n",
    "Allow hook to access internals of XResNet by unpacking arg list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_new = nn.Sequential(\n",
    "    *m_cut.children(), AdaptiveConcatPool2d(), Flatten(),\n",
    "    nn.Linear(ni*2, data.c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_new_deep = nn.Sequential(\n",
    "    *m_gc, AdaptiveConcatPool2d(), Flatten(),\n",
    "    nn.Linear(ni*2, data.c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_new_shallow = nn.Sequential(\n",
    "    m_cut, AdaptiveConcatPool2d(), Flatten(),\n",
    "    nn.Linear(ni*2, data.c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HOOK_DEPTH=='deep':\n",
    "    learn.model = m_new_deep\n",
    "elif HOOK_DEPTH=='base':\n",
    "    learn.model = m_new\n",
    "elif HOOK_DEPTH=='shallow':\n",
    "    learn.model = m_new_shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran telemetry previously in lesson 10 (nb 06), were were using a manually built model with 7 layers:\n",
    "\n",
    "<pre>\n",
    "    Sequential(\n",
    "  (0): Sequential(\n",
    "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "    (1): ReLU()\n",
    "  )\n",
    "  (1): Sequential(\n",
    "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    (1): ReLU()\n",
    "  )\n",
    "  (2): Sequential(\n",
    "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    (1): ReLU()\n",
    "  )\n",
    "  (3): Sequential(\n",
    "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    (1): ReLU()\n",
    "  )\n",
    "  (4): AdaptiveAvgPool2d(output_size=1)\n",
    "  (5): Lambda()\n",
    "  (6): Linear(in_features=32, out_features=10, bias=True)\n",
    ")\n",
    "</pre>\n",
    "\n",
    "Like the code below the AdaptiveAvgPool2d and Lambda (below we use Flatten) have the same output data-ie same plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[batch_size, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Hooks(learn.model, append_hist_stats) as hooks_basic_naive: \n",
    "#    learn.fit(1, cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='82' class='' max='105', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      78.10% [82/105 01:01<00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5\n",
    "with Hooks(learn.model, append_hist_delta_stats) as hooks_naive: \n",
    "    learn.fit(5, cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'iteration: {stat_iter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "epoch \ttrain_loss \ttrain_accuracy \tvalid_loss \tvalid_accuracy \ttime\n",
    "0 \t2.852017 \t0.287686 \t2.486142 \t0.387275 \t00:08\n",
    "1 \t2.179299 \t0.469177 \t2.641399 \t0.352697 \t00:07\n",
    "2 \t2.030308 \t0.531273 \t2.449481 \t0.413555 \t00:07\n",
    "3 \t1.731837 \t0.638368 \t1.788130 \t0.615491 \t00:07\n",
    "4 \t1.465440 \t0.747413 \t1.599652 \t0.690180 \t00:07\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks(hooks_naive,fig_name='naive_stats.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hooks_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_delta_hist(hooks_naive,fig_name='naive_delta_hists.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_hist(hooks_naive,fig_name='naive_hists.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_mid_mins(hooks_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_stats(hooks_data):\n",
    "    histsl=[]\n",
    "    msl=[]\n",
    "    ssl=[]\n",
    "    for h in hooks_data:\n",
    "        histsl.append(get_hist(h))\n",
    "        ms,ss, hists = h.stats\n",
    "        msl.append(ms)\n",
    "        ssl.append(ss)\n",
    "    del_ms=np.diff(msl)\n",
    "    del_ss=np.diff(ssl)\n",
    "    return del_ms,del_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_del_ms,naive_del_ss=diff_stats(hooks_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means change between each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(naive_del_ms, 50,fig_name='naive_del_ms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(naive_del_ss, 50,fig_name='naive_del_sds.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means change between first and last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_last = [naive_del_ms[0], naive_del_ms[-1]]\n",
    "print(len(first_n_last))\n",
    "naive_del_fal=np.diff(first_n_last)\n",
    "print(len(naive_del_fal))\n",
    "plot_deltas(naive_del_fal, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.recorder.losses)/len(learn.recorder.val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18.5 * more training data than validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear mem\n",
    "naive_del_ms=None\n",
    "naive_del_ss=None\n",
    "hooks_naive=None\n",
    "naive_del_fal=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adapt_model and gradual unfreezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines above pasted into one cell to create a function (Shift-M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_model(learn, data):\n",
    "    cut = next(i for i,o in enumerate(learn.model.children())\n",
    "               if isinstance(o,nn.AdaptiveAvgPool2d))\n",
    "    m_cut = learn.model[:cut]\n",
    "    xb,yb = get_batch(data.valid_dl, learn)\n",
    "    pred = m_cut(xb)\n",
    "    ni = pred.shape[1]\n",
    "    m_new = nn.Sequential(\n",
    "        #replace m_cut with children to get data for each layer in XResNet\n",
    "        *m_cut.children(), AdaptiveConcatPool2d(), Flatten(),\n",
    "        nn.Linear(ni*2, data.c_out))\n",
    "    learn.model = m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_deep_model(learn, data):\n",
    "    cut = next(i for i,o in enumerate(learn.model.children())\n",
    "               if isinstance(o,nn.AdaptiveAvgPool2d))\n",
    "    m_cut = learn.model[:cut]\n",
    "    m_gc = module_grandchildren(m_cut)\n",
    "    xb,yb = get_batch(data.valid_dl, learn)\n",
    "    pred = m_cut(xb)\n",
    "    ni = pred.shape[1]\n",
    "    m_new = nn.Sequential(\n",
    "        #replace m_cut with grandchildren to get data for each layer in XResNet\n",
    "        *m_gc, AdaptiveConcatPool2d(), Flatten(),\n",
    "        nn.Linear(ni*2, data.c_out))\n",
    "    learn.model = m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_simple_model(learn, data):\n",
    "    cut = next(i for i,o in enumerate(learn.model.children())\n",
    "               if isinstance(o,nn.AdaptiveAvgPool2d))\n",
    "    m_cut = learn.model[:cut]\n",
    "    xb,yb = get_batch(data.valid_dl, learn)\n",
    "    pred = m_cut(xb)\n",
    "    ni = pred.shape[1]\n",
    "    m_new = nn.Sequential(\n",
    "        m_cut, AdaptiveConcatPool2d(), Flatten(),\n",
    "        nn.Linear(ni*2, data.c_out))\n",
    "    learn.model = m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette, xtra_cb=Recorder)\n",
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HOOK_DEPTH=='deep':\n",
    "    adapt_deep_model(learn, data)\n",
    "elif HOOK_DEPTH=='base':\n",
    "    adapt_model(learn, data)\n",
    "elif HOOK_DEPTH=='shallow':\n",
    "    adapt_simple_model(learn, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic model as per lesson len: 4, with children len: 11, with grandchildren len: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.model); HOOK_DEPTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab all parameters in the body (the m_cut bit) and dont train these - just train the head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze everything before head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything before AdaptiveConcatPool2d \n",
    "for i in range(len(learn.model)-3):\n",
    "    for p in learn.model[0].parameters(): p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(learn.model, append_hist_delta_stats) as hooks_freeze: \n",
    "    learn.fit(3, sched_1cycle(1e-2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks(hooks_freeze,fig_name='freeze_layer_stats.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_hooks_hist(hooks_freeze,fig_name='freeze_hists.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_delta_hist(hooks_freeze,fig_name='freeze_delta_hists.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_mid_mins(hooks_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_del_ms,frozen_del_ss=diff_stats(hooks_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(frozen_del_ms, 50,fig_name='freeze_del_ms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(frozen_del_ss, 50,fig_name='freeze_del_sds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear mem\n",
    "frozen_del_ms=None\n",
    "frozen_del_ss=None\n",
    "hooks_freeze=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything before AdaptiveConcatPool2d - note difference to lesson nb where just have layer 0\n",
    "for i in range(len(learn.model)-3):\n",
    "    for p in learn.model[i].parameters(): p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(learn.model, append_hist_delta_stats) as hooks_unfreeze: \n",
    "    learn.fit(5, cbsched, reset_opt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In frozen layer - train for particuar mean and std dev, but pets has different std dev and means inside the model.\n",
    "\n",
    "What is really going on here? (1:26 in lesson video), and why do I get better results when JH got worse result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks(hooks_unfreeze,fig_name='unfreeze_layer_stats.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_hooks_hist(hooks_unfreeze,fig_name='unfreeze_hists.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_delta_hist(hooks_unfreeze,fig_name='unfreeze_delta_hists.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_mid_mins(hooks_unfreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfrozen_del_ms,unfrozen_del_ss=diff_stats(hooks_unfreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(unfrozen_del_ms, 50,fig_name='unfreeze_del_ms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(unfrozen_del_ss, 50,fig_name='unfreeze_del_sds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze only layer params that aren't in the batch norm layers\n",
    "\n",
    "1:27 in lesson 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear mem\n",
    "unfrozen_del_ms=None\n",
    "unfrozen_del_ss=None\n",
    "hooks_unfreeze=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch norm transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all params that are not in the batchnorm layer or linear layer at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette, xtra_cb=Recorder)\n",
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n",
    "adapt_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mod(m, f):\n",
    "    f(m)\n",
    "    for l in m.children(): apply_mod(l, f)\n",
    "\n",
    "def set_grad(m, b):\n",
    "    #if linear layer (at end) or batchnorm layer in middle, dont change the gradient\n",
    "    print(type(m))\n",
    "    if isinstance(m, (nn.Linear,nn.BatchNorm2d)): return\n",
    "    if hasattr(m, 'weight'):\n",
    "        for p in m.parameters(): p.requires_grad_(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze and fit\n",
    "\n",
    "Freeze just non batchnorm and last layer, note using apply_mod we traverse children layers so can access Batchnorm layers inside sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mod(learn.model, partial(set_grad, b=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run out of mem with deltas\n",
    "with Hooks(learn.model, append_hist_stats) as hooks_freeze_non_bn: \n",
    "    learn.fit(3, sched_1cycle(1e-2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks(hooks_freeze_non_bn,fig_name='freeze_non_bn_layers.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_hist(hooks_freeze_non_bn,fig_name='freeze_non_bn_hist.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_hooks_delta_hist(hooks_freeze_non_bn,fig_name='freeze_non_bn_delta_hist.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_mins(hooks_freeze_non_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_non_bn_del_ms,freeze_non_bn_del_sds=diff_stats(hooks_freeze_non_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(freeze_non_bn_del_ms, 50,fig_name='freeze_non_bn_del_ms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(freeze_non_bn_del_sds, 50,fig_name='freeze_non_bn_del_sds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mod(learn.model, partial(set_grad, b=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(learn.model, append_hist_stats) as hooks_unfreeze_non_bn: \n",
    "    learn.fit(5, cbsched, reset_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks(hooks_unfreeze_non_bn,fig_name='unfreeze_non_bn_layers.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_hist(hooks_unfreeze_non_bn,fig_name='unfreeze_non_bn_hist.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_hooks_delta_hist(hooks_unfreeze_non_bn,fig_name='unfreeze_non_bn_delta_hist.png',model=learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_mins(hooks_unfreeze_non_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_non_bn_del_ms,unfreeze_non_bn_del_sds=diff_stats(hooks_unfreeze_non_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(unfreeze_non_bn_del_ms, 50,fig_name='unfreeze_non_bn_del_ms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deltas(unfreeze_non_bn_del_sds, 50,fig_name='unfreeze_non_bn_del_sds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch already has an `apply` method we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.apply(partial(set_grad, b=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson 12 video: 1:29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative LR and param groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_simple_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_splitter(m):\n",
    "    def _bn_splitter(l, g1, g2):\n",
    "        if isinstance(l, nn.BatchNorm2d): \n",
    "            g2 += l.parameters()\n",
    "        elif hasattr(l, 'weight'): \n",
    "            g1 += l.parameters()\n",
    "        for ll in l.children(): \n",
    "            _bn_splitter(ll, g1, g2)\n",
    "        \n",
    "    g1,g2 = [],[]\n",
    "    _bn_splitter(m[0], g1, g2)\n",
    "    \n",
    "    g2 += m[1:].parameters()\n",
    "    return g1,g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = bn_splitter(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(m.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(a)+len(b), len(list(m.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learner.ALL_CBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from types import SimpleNamespace\n",
    "cb_types = SimpleNamespace(**{o:o for o in Learner.ALL_CBS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_types.after_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DebugCallback(Callback):\n",
    "    _order = 999\n",
    "    def __init__(self, cb_name, f=None): self.cb_name,self.f = cb_name,f\n",
    "    def __call__(self, cb_name):\n",
    "        if cb_name==self.cb_name:\n",
    "            if self.f: self.f(self.run)\n",
    "            else:      set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr  = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "                 for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr),\n",
    "            ParamScheduler('mom', sched_mom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_lr_sched = sched_1cycle([0,3e-2], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func,\n",
    "                    c_out=10, norm=norm_imagenette, splitter=bn_splitter)\n",
    "\n",
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n",
    "adapt_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_det(o): \n",
    "    print (len(o.opt.param_groups), o.opt.hypers)\n",
    "    raise CancelTrainException()\n",
    "\n",
    "learn.fit(1, disc_lr_sched + [DebugCallback(cb_types.after_batch, _print_det)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_lr_sched = sched_1cycle([1e-3,1e-2], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(5, disc_lr_sched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!./notebook2script.py 11a_transfer_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
